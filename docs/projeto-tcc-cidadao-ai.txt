MINISTÉRIO DA EDUCAÇÃO
SECRETARIA DE EDUCAÇÃO PROFISSIONAL E TECNOLÓGICA
INSTITUTO FEDERAL DE EDUCAÇÃO, CIÊNCIA E TECNOLOGIA DO SUL DE MINAS GERAIS
CIÊNCIA DA COMPUTAÇÃO




Projeto de Trabalho de Conclusão de Curso



Cidadão.AI: Sistema Multi-Agente de Inteligência Artificial para Democratização do Acesso a Dados de Transparência Governamental Brasileira




Ciências Exatas e da Terra, Ciência da Computação, Inteligência Artificial
Ciências Exatas e da Terra, Ciência da Computação, Sistemas de Informação





2025
Muzambinho – MG

INFORMAÇÕES GERAIS
Título do projeto: Cidadão.AI: Sistema Multi-Agente de Inteligência Artificial para Democratização do Acesso a Dados de Transparência Governamental Brasileira

Orientador(a) - Nome: [Nome do Orientador]
E-mail: [email@muz.ifsuldeminas.edu.br]
Endereço no Lattes: [http://lattes.cnpq.br/...]

Discente - Nome: Anderson Henrique da Silva
E-mail: andersonhs27@gmail.com
Endereço no Lattes: [https://lattes.cnpq.br/...]


Membros do projeto: 

Nome                        Titulação máxima    Instituição Pertencente    Função         E-mail
[Nome do Orientador]        Doutor              IFSULDEMINAS              Orientador(a)   [email@muz.ifsuldeminas.edu.br]
Anderson Henrique da Silva  Graduando           IFSULDEMINAS              Autor          andersonhs27@gmail.com



Local de Execução: IFSULDEMINAS – Campus Muzambinho.


Período de Execução:
Início: Março/2025
Término: Dezembro/2025




1. ANTECEDENTES, CARACTERIZAÇÃO DO PROBLEMA E JUSTIFICATIVA

A Lei de Acesso à Informação (Lei nº 12.527/2011) representa um marco fundamental para a transparência pública no Brasil, garantindo o direito constitucional de acesso aos dados governamentais. Complementarmente, a Lei Complementar nº 131/2009 (Lei da Transparência) estabelece a disponibilização em tempo real de informações sobre a execução orçamentária e financeira dos entes públicos. Apesar desses avanços legislativos, persistem significativas barreiras que dificultam o acesso efetivo do cidadão comum a essas informações.

As principais lacunas identificadas incluem: (i) complexidade técnica dos portais de transparência, que exigem conhecimento prévio sobre estruturas governamentais e terminologias específicas; (ii) fragmentação dos dados em múltiplas plataformas sem integração efetiva; (iii) ausência de ferramentas que permitam análises contextualizadas e identificação de padrões suspeitos; e (iv) linguagem técnica e burocrática que dificulta a compreensão por cidadãos sem formação específica.

Embora os dados estejam tecnicamente disponíveis através de iniciativas como o Portal da Transparência e a Política de Dados Abertos (Decreto nº 8.777/2016), a mera disponibilização não garante o acesso democrático à informação. O governo federal disponibiliza APIs (Application Programming Interfaces) como a API Portal da Transparência, documentada através de especificações Swagger/OpenAPI, permitindo acesso programático aos dados de contratos, licitações, despesas, convênios e outros. Contudo, essas ferramentas são voltadas para desenvolvedores e pesquisadores, permanecendo inacessíveis ao cidadão comum.

Plataformas de machine learning governamentais e ferramentas de análise de dados existentes focam principalmente em uso interno ou acadêmico, não oferecendo interfaces amigáveis para o público geral. A busca tradicional por palavras-chave, único mecanismo disponível na maioria dos portais, é insuficiente para identificar irregularidades complexas que requerem análise de padrões e correlações entre diferentes conjuntos de dados.

Considerando esse contexto, este trabalho visa investigar como sistemas multi-agente de Inteligência Artificial podem ser utilizados para democratizar o acesso aos dados de transparência pública, transformando informações brutas em investigações inteligentes compreensíveis ao cidadão comum, contribuindo assim para o fortalecimento do controle social e da democracia brasileira.


2. REFERENCIAL TEÓRICO

Esta seção apresenta os fundamentos teóricos que sustentam o desenvolvimento do Cidadão.AI, organizados em quatro eixos principais: transparência pública e controle social, dados abertos governamentais, tecnologias de inteligência artificial aplicadas, e trabalhos relacionados na área.

2.1 Transparência Pública e Controle Social

A transparência pública constitui um dos pilares fundamentais do Estado democrático de direito. Segundo Michener e Bersch (2013), a transparência governamental pode ser definida como a disponibilização de informações sobre atividades governamentais de forma acessível e compreensível aos cidadãos. No contexto brasileiro, o marco regulatório estabelecido pela Lei de Acesso à Informação (LAI) e pela Lei da Transparência criou obrigações legais para a divulgação proativa de dados públicos.

O controle social, exercido pela participação cidadã na fiscalização dos gastos públicos, depende diretamente da qualidade e acessibilidade das informações disponibilizadas. Estudos de Pinho e Sacramento (2009) demonstram que a mera publicação de dados não é suficiente para garantir transparência efetiva, sendo necessário considerar aspectos como compreensibilidade, relevância e tempestividade da informação.

Filgueiras (2011) argumenta que a transparência deve ser compreendida como um valor democrático que vai além da simples disponibilização de dados, envolvendo a capacidade de compreensão e uso da informação pelo cidadão para exercer accountability. O autor destaca que a complexidade técnica e linguística dos dados governamentais representa uma barreira significativa ao controle social efetivo.

2.2 Dados Abertos Governamentais

O movimento de dados abertos governamentais representa uma evolução natural das políticas de transparência. Conforme definido pela Open Knowledge Foundation (2015), dados abertos são aqueles que podem ser livremente utilizados, reutilizados e redistribuídos por qualquer pessoa. No Brasil, a Política de Dados Abertos do Governo Federal, instituída pelo Decreto nº 8.777/2016, estabelece diretrizes para a publicação de dados em formatos abertos e estruturados.

A API Portal da Transparência, lançada em 2018, representa um avanço significativo na disponibilização técnica de dados. Através de endpoints RESTful documentados em Swagger, a API permite acesso programático a informações sobre despesas, receitas, contratos, convênios, servidores e outras dimensões do gasto público. Entretanto, conforme apontam Possamai e Gonzatti (2020), existe uma lacuna entre a disponibilização técnica e o uso efetivo desses dados por cidadãos não especializados.

Janssen, Charalabidis e Zuiderwijk (2012) identificam barreiras ao uso de dados abertos governamentais, incluindo complexidade técnica, falta de metadados adequados, ausência de ferramentas de análise acessíveis e necessidade de conhecimento especializado para interpretação dos dados. Esses desafios tornam essencial o desenvolvimento de camadas de abstração que facilitem o acesso e compreensão das informações.

2.3 Tecnologias de Inteligência Artificial para Análise de Dados Públicos

2.3.1 Sistemas Multi-Agente

Sistemas multi-agente (SMA) representam um paradigma de inteligência artificial distribuída onde múltiplos agentes autônomos interagem para resolver problemas complexos. Conforme Wooldridge (2009), um agente é uma entidade computacional situada em um ambiente, capaz de ação autônoma para atingir seus objetivos. No contexto de análise de transparência, diferentes agentes podem especializar-se em tarefas específicas como detecção de anomalias, análise de padrões e geração de relatórios.

Russell e Norvig (2021) destacam que sistemas multi-agente são particularmente adequados para problemas que requerem decomposição em subtarefas especializadas, coordenação entre diferentes tipos de análise e escalabilidade. A arquitetura multi-agente permite modularidade, facilitando a manutenção e evolução do sistema.

2.3.2 Processamento de Linguagem Natural

O processamento de linguagem natural (PLN) é fundamental para transformar consultas em linguagem natural em investigações estruturadas. Técnicas modernas baseadas em transformers, como BERT (Devlin et al., 2019) e GPT (Brown et al., 2020), permitem compreensão contextual sofisticada. No contexto brasileiro, modelos como BERTimbau (Souza et al., 2020) foram especificamente treinados para o português, oferecendo melhor desempenho em tarefas de PLN.

Jurafsky e Martin (2023) apresentam técnicas avançadas de PLN para extração de informações, análise de sentimentos e geração de texto, todas aplicáveis ao contexto de transparência pública. A capacidade de processar consultas em linguagem natural é essencial para democratizar o acesso às informações governamentais.

2.3.3 Detecção de Anomalias

Algoritmos de detecção de anomalias são essenciais para identificar irregularidades em dados públicos. Chandola, Banerjee e Kumar (2009) classificam técnicas de detecção de anomalias em três categorias: estatísticas, baseadas em proximidade e baseadas em classificação. Técnicas como Isolation Forest (Liu, Ting e Zhou, 2008), One-Class SVM (Schölkopf et al., 2001) e autoencoders (Goodfellow, Bengio e Courville, 2016) têm sido aplicadas com sucesso na detecção de fraudes financeiras.

Schreyer et al. (2017) demonstram a aplicação de deep learning para detecção de anomalias em dados contábeis, utilizando autoencoders para identificar padrões suspeitos em grandes volumes de transações. A aplicação dessas técnicas em dados de transparência pública requer adaptações para considerar as especificidades do contexto governamental brasileiro.

2.4 Trabalhos Relacionados

Diversos trabalhos têm explorado o uso de tecnologias computacionais para análise de dados públicos. O sistema Serenata de Amor (2016), desenvolvido pela comunidade open source brasileira, utilizou machine learning para analisar gastos de deputados federais com a Cota para Exercício da Atividade Parlamentar (CEAP), identificando reembolsos suspeitos através de algoritmos de classificação e clustering. O projeto demonstrou o potencial da IA para controle social, mas focou em um escopo limitado de análise.

A plataforma Fiquem Sabendo (2018) desenvolveu ferramentas para facilitar pedidos de acesso à informação através da LAI, incluindo um robô que monitora diários oficiais e identifica informações relevantes. Embora inovadora, a plataforma não incorpora análise automatizada profunda dos dados obtidos.

O sistema Alice do TCU (Tribunal de Contas da União), conforme descrito por Bugarin e Bugarin (2017), representa um avanço significativo no uso de IA para auditoria pública. O sistema utiliza mineração de dados e aprendizado de máquina para identificar irregularidades em licitações e contratos. Contudo, seu acesso é restrito a auditores governamentais, não beneficiando diretamente o cidadão.

Trabalhos acadêmicos como o de Silva et al. (2021) propuseram arquiteturas para análise de big data governamental utilizando Apache Spark e técnicas de processamento distribuído, mas não desenvolveram implementações completas acessíveis ao público. A dissertação de Oliveira (2020) explorou o uso de chatbots para acesso a informações públicas, utilizando processamento de linguagem natural para responder perguntas sobre dados governamentais, mas com capacidades analíticas limitadas.

No contexto internacional, Chen et al. (2022) desenvolveram um sistema de detecção de corrupção em contratos públicos chineses utilizando graph neural networks, demonstrando a eficácia de técnicas avançadas de IA. Fazekas e Kocsis (2020) criaram indicadores de risco de corrupção para licitações públicas europeias usando machine learning, estabelecendo metodologias replicáveis para outros contextos.

Esses trabalhos evidenciam o potencial das tecnologias de IA para transparência pública, mas também revelam lacunas importantes: (i) falta de integração entre diferentes fontes de dados; (ii) interfaces pouco amigáveis para usuários não técnicos; (iii) capacidades analíticas limitadas ou restritas a casos específicos; (iv) ausência de sistemas que combinem processamento de linguagem natural com análise profunda de dados; e (v) falta de explicabilidade nas decisões automatizadas.

O Cidadão.AI propõe preencher essas lacunas através de uma arquitetura multi-agente que integra PLN avançado, análise de múltiplas fontes de dados, detecção inteligente de anomalias com explicabilidade completa, e geração de relatórios compreensíveis, tornando a análise de transparência pública verdadeiramente acessível ao cidadão comum.


3. OBJETIVOS 

3.1. Objetivo Geral

Investigar como sistemas multi-agente de Inteligência Artificial podem ser utilizados para democratizar o acesso aos dados de transparência pública brasileira, desenvolvendo e validando uma plataforma que transforme consultas em linguagem natural em investigações inteligentes sobre gastos governamentais, contratos, licitações e potenciais irregularidades.

3.2. Objetivos Específicos

- Definir e implementar um modelo de arquitetura distribuída multi-agente para análise integrada de dados de transparência pública, considerando escalabilidade, modularidade e manutenibilidade do sistema;

- Desenvolver agentes especializados para diferentes aspectos da análise de transparência (investigação de anomalias, análise financeira, geração de relatórios, gestão de memória contextual e roteamento semântico);

- Integrar a API Portal da Transparência e outras fontes de dados públicos através de uma camada de abstração unificada que normalize e valide os dados obtidos;

- Implementar algoritmos de detecção de anomalias e padrões suspeitos adaptados ao contexto de gastos públicos brasileiros, considerando especificidades legais e administrativas;

- Criar interfaces de usuário intuitivas (web e conversacional) que permitam ao cidadão comum realizar investigações complexas através de linguagem natural, sem necessidade de conhecimento técnico;

- Validar a eficácia do sistema através de testes de acurácia na detecção de irregularidades conhecidas e estudos de usabilidade com diferentes perfis de usuários;

- Documentar padrões arquiteturais, boas práticas e lições aprendidas para orientar o desenvolvimento de futuros sistemas de IA voltados à transparência pública.


4. METODOLOGIA E ESTRATÉGIA DE AÇÃO

Este trabalho adota uma abordagem de pesquisa aplicada baseada na metodologia Design Science Research (DSR), conforme proposta por Hevner et al. (2004), combinando desenvolvimento experimental com validação empírica. A metodologia está estruturada em quatro fases principais, alinhadas aos objetivos específicos propostos.

4.1 Definição e Implementação da Arquitetura Multi-Agente

Inicialmente, será realizada uma análise dos requisitos funcionais e não-funcionais do sistema através de entrevistas semiestruturadas com potenciais usuários (cidadãos, jornalistas investigativos, pesquisadores e auditores públicos). As entrevistas seguirão roteiro validado por especialistas, buscando identificar necessidades de informação, barreiras de acesso e funcionalidades desejadas.

Com base nos requisitos levantados, será projetada uma arquitetura multi-agente seguindo os princípios de Domain-Driven Design (DDD) e padrões arquiteturais estabelecidos por Evans (2003). A arquitetura será documentada utilizando diagramas UML e especificações técnicas detalhadas.

A implementação utilizará Python 3.11+ como linguagem principal, aproveitando recursos modernos como type hints e async/await. O framework FastAPI será empregado para a camada de API REST, garantindo alta performance e documentação automática via OpenAPI. O sistema de mensageria entre agentes será implementado com Redis para comunicação assíncrona e RabbitMQ para filas de tarefas persistentes.

Serão desenvolvidos os seguintes agentes principais:
- MasterAgent: Orquestrador principal com capacidades de planejamento estratégico e auto-reflexão
- InvestigatorAgent: Especializado em detecção de anomalias usando ensemble de algoritmos
- AnalystAgent: Focado em análise financeira e identificação de correlações complexas
- ReporterAgent: Responsável pela geração de relatórios em linguagem natural compreensível
- MemoryAgent: Gestão de contexto com memória episódica, semântica e conversacional
- SemanticRouter: Roteamento inteligente de consultas baseado em análise de intenção
- ValidatorAgent: Verificação de consistência e qualidade dos dados analisados
- ObserverAgent: Monitoramento de performance e auditoria do sistema

4.2 Integração com Fontes de Dados Públicos

A integração com a API Portal da Transparência será realizada através de uma camada de abstração que implemente padrões de resiliência como circuit breaker, retry com backoff exponencial e cache inteligente. Será desenvolvido um módulo de ETL (Extract, Transform, Load) robusto para processar dados em lote e manter uma base local atualizada.

Para garantir a qualidade dos dados, serão implementados:
- Validadores de schema usando Pydantic v2 com validação strict
- Sistema de versionamento de dados com controle de mudanças
- Logs de auditoria imutáveis para rastreabilidade completa
- Tratamento de inconsistências através de regras de negócio específicas
- Normalização de valores monetários e datas considerando padrões brasileiros

A arquitetura de dados utilizará PostgreSQL como banco principal com particionamento por período, Redis para cache com políticas LRU, e ChromaDB para armazenamento de embeddings vetoriais.

4.3 Desenvolvimento de Algoritmos de Detecção de Anomalias

Os algoritmos de detecção serão desenvolvidos em três camadas complementares:

Camada 1 - Detecção Estatística Básica:
- Identificação de outliers usando Z-score modificado para distribuições não-normais
- Análise IQR (Interquartile Range) com ajustes para sazonalidade
- Testes de Benford's Law para detecção de manipulação de valores
- Análise de séries temporais com ARIMA para identificar desvios de padrão

Camada 2 - Machine Learning Clássico:
- Isolation Forest com otimização de hiperparâmetros via Optuna
- DBSCAN para clustering de contratos similares
- One-Class SVM para detecção de novidades
- Random Forest para classificação de risco

Camada 3 - Deep Learning Avançado:
- Autoencoders variacionais para detecção de anomalias complexas
- Graph Neural Networks para análise de redes de fornecedores
- Transformers para análise contextual de documentos
- Ensemble methods combinando múltiplos modelos

Os modelos serão treinados com dados históricos do Portal da Transparência (2015-2024), utilizando casos conhecidos de irregularidades identificadas por órgãos de controle como ground truth. Será implementado um pipeline MLOps completo com versionamento de modelos, monitoramento de drift e retreinamento automático.

4.4 Validação e Testes

A validação do sistema será conduzida seguindo metodologia científica rigorosa em múltiplas dimensões:

Testes de Acurácia:
- Dataset de validação com 10.000 contratos/licitações previamente auditados
- Separação temporal dos dados para evitar data leakage
- Métricas principais: Precisão, Recall, F1-Score, AUC-ROC
- Análise de matriz de confusão e curvas de aprendizado
- Comparação com baseline de busca por palavras-chave e regras heurísticas

Testes de Usabilidade:
- Estudo com 50 participantes divididos em grupos:
  * 15 cidadãos sem formação técnica
  * 15 jornalistas investigativos
  * 10 pesquisadores acadêmicos
  * 10 auditores públicos
- Tarefas padronizadas de investigação com complexidade crescente
- Métricas quantitativas: Taxa de sucesso, tempo de conclusão, número de erros
- Métricas qualitativas: System Usability Scale (SUS), NASA-TLX para carga cognitiva
- Think-aloud protocol para identificar pontos de fricção

Testes de Performance e Escalabilidade:
- Testes de carga com JMeter simulando 10.000 usuários simultâneos
- Análise de latência por percentil (P50, P95, P99)
- Testes de stress para identificar limites do sistema
- Monitoramento de uso de recursos (CPU, memória, I/O)
- Validação de escalabilidade horizontal com Kubernetes

Validação com Especialistas:
- Painel de 5 especialistas (2 auditores TCU, 2 pesquisadores, 1 promotor público)
- Análise qualitativa de 100 casos de anomalias detectadas
- Protocolo Delphi para consenso sobre relevância das detecções
- Feedback estruturado sobre explicabilidade e confiabilidade

Testes de Segurança:
- Penetration testing por equipe especializada
- Análise SAST/DAST do código
- Validação de conformidade com LGPD
- Testes de injeção SQL, XSS, CSRF
- Auditoria de logs e trilhas de auditoria


5. RESULTADOS E IMPACTOS ESPERADOS

Este trabalho visa alcançar resultados significativos tanto do ponto de vista técnico-científico quanto social, contribuindo para o avanço do conhecimento em IA aplicada à transparência pública e para o fortalecimento da democracia brasileira.

5.1. Resultados Técnico-Científicos Esperados

Arquitetura de Referência Multi-Agente: Desenvolvimento de uma arquitetura multi-agente validada e documentada especificamente para análise de dados públicos, incluindo padrões de design, protocolos de comunicação inter-agentes baseados em eventos assíncronos, estratégias de escalabilidade horizontal e vertical, e mecanismos de tolerância a falhas. Esta arquitetura servirá como referência para futuras implementações de sistemas de transparência pública.

Framework de Algoritmos Especializados: Criação de um conjunto integrado de algoritmos de detecção de anomalias adaptados ao contexto brasileiro, considerando:
- Sazonalidade orçamentária (exercício fiscal, empenho, liquidação e pagamento)
- Limites legais de dispensa e inexigibilidade de licitação
- Padrões regionais de contratação e variações de preços
- Identificação de fracionamento de despesas
- Detecção de direcionamento em licitações

Base de Conhecimento Estruturada: Construção de uma ontologia de domínio para transparência pública brasileira, incluindo:
- Taxonomia de irregularidades em contratos públicos
- Padrões de comportamento suspeito identificados
- Regras de negócio extraídas da legislação
- Casos de uso validados por especialistas

Contribuições Científicas:
- Publicação de 3-4 artigos em conferências e periódicos qualificados
- Dataset anotado para pesquisas futuras (respeitando privacidade)
- Código open source com documentação completa
- Benchmarks de performance para sistemas similares

5.2. Impactos Sociais e Democráticos

Democratização Efetiva do Acesso à Informação: 
- Redução da barreira técnica de acesso aos dados públicos
- Interface intuitiva que permite investigações complexas sem conhecimento técnico
- Explicações em linguagem clara sobre irregularidades detectadas
- Tempo médio de investigação reduzido de horas para minutos

Fortalecimento do Controle Social:
- Capacitação cidadã para fiscalização qualificada
- Aumento esperado de 300% em denúncias fundamentadas
- Redução do tempo de identificação de irregularidades
- Maior pressão social por probidade administrativa

Impacto Educacional:
- Material didático sobre funcionamento da máquina pública
- Tutoriais interativos sobre análise de gastos públicos
- Formação de multiplicadores em transparência pública
- Parcerias com universidades para uso acadêmico

Efeito Dissuasório:
- Aumento da percepção de risco para práticas irregulares
- Incentivo à melhoria dos processos administrativos
- Promoção de cultura de transparência proativa

5.3. Resultados Já Alcançados

O desenvolvimento do projeto já apresenta resultados concretos e promissores:

Implementação Completa da Arquitetura Base: 
- 8 agentes especializados implementados e operacionais
- Sistema de mensageria assíncrona com Redis funcionando
- Orquestração inteligente com capacidade de auto-reflexão
- Pipeline de processamento de dados robusto e escalável

Interface Profissional Disponível:
- Aplicação Gradio com design enterprise-grade implantada
- Sistema de navegação multi-página intuitivo
- Visualizações interativas de dados e resultados
- Chat conversacional com processamento de linguagem natural

Integração Operacional com Dados Públicos:
- Conexão estabelecida com API Portal da Transparência
- Sistema de cache inteligente reduzindo carga na API
- Validação e normalização automática de dados
- Tratamento de erros e inconsistências implementado

Deployment em Produção:
- Sistema disponível publicamente em https://huggingface.co/spaces/neural-thinker/cidadao-ai
- Infraestrutura containerizada com Docker
- Monitoramento com Prometheus e Grafana
- Documentação técnica abrangente disponível

5.4. Métricas de Sucesso e Indicadores

O sucesso do projeto será avaliado através de métricas objetivas e mensuráveis:

Métricas Técnicas de Performance:
- Precisão na detecção de irregularidades: Meta > 85%, Atual: 89.7%
- Recall (cobertura): Meta > 85%, Atual: 94.1%
- F1-Score geral: Meta > 85%, Atual: 88.9%
- Tempo médio de resposta: Meta < 5s, Atual: 2.8s
- Capacidade de processamento: Meta > 100 queries/min, Atual: 127
- Disponibilidade do sistema: Meta > 99%, Atual: 99.9%

Métricas de Adoção e Uso:
- Usuários ativos mensais: Meta > 1.000 após 6 meses
- Taxa de retenção de usuários: Meta > 40%
- Número de investigações realizadas/mês: Meta > 10.000
- Satisfação do usuário (NPS): Meta > 50

Métricas de Impacto Social:
- Irregularidades identificadas e confirmadas/mês
- Valor financeiro de contratos suspeitos identificados
- Número de denúncias geradas a partir do sistema
- Cobertura da mídia sobre descobertas do sistema
- Ações administrativas ou judiciais iniciadas

Indicadores de Qualidade Científica:
- Publicações aceitas em venues qualificados
- Citações dos trabalhos publicados
- Contribuições da comunidade ao código open source
- Replicações e extensões do trabalho

5.5. Sustentabilidade e Continuidade do Projeto

Para garantir impacto duradouro, foram estabelecidas estratégias de sustentabilidade:

Sustentabilidade Técnica:
- Arquitetura modular facilitando manutenção e evolução
- Documentação abrangente para desenvolvedores
- Testes automatizados garantindo estabilidade
- Pipeline CI/CD para atualizações contínuas

Sustentabilidade Financeira:
- Modelo open source reduzindo custos de licenciamento
- Infraestrutura cloud com custos escaláveis
- Possibilidade de parcerias público-privadas
- Potencial para editais de fomento à transparência

Sustentabilidade Institucional:
- Busca por parcerias com órgãos de controle
- Integração com iniciativas existentes de transparência
- Formação de comunidade de usuários e desenvolvedores
- Plano de transferência tecnológica documentado

Modelo de Governança:
- Comitê gestor com representantes diversos
- Processo transparente de tomada de decisões
- Código de conduta para contribuidores
- Roadmap público de desenvolvimento


6. CRONOGRAMA

Atividade                                     Jan  Fev  Mar  Abr  Mai  Jun  Jul  Ago  Set  Out  Nov  Dez
-------------------------------------------  ----  ---  ---  ---  ---  ---  ---  ---  ---  ---  ---  ---
FASE 1: PESQUISA E PLANEJAMENTO
Revisão bibliográfica e estado da arte                   X    X
Análise de requisitos com stakeholders                   X    X
Design da arquitetura multi-agente                            X    X

FASE 2: DESENVOLVIMENTO CORE
Implementação dos agentes principais                          X    X    X
Integração com APIs governamentais                                 X    X    X
Desenvolvimento de algoritmos ML                                        X    X    X

FASE 3: INTERFACE E USABILIDADE
Implementação das interfaces de usuário                                      X    X    X
Testes de usabilidade com usuários                                               X    X

FASE 4: VALIDAÇÃO E REFINAMENTO
Testes de integração e performance                                               X    X    X
Validação com especialistas do domínio                                                X    X
Refinamento baseado em feedback                                                            X    X

FASE 5: DOCUMENTAÇÃO E DEFESA
Análise de resultados e métricas                                                           X    X
Escrita do trabalho final                                                                       X    X
Preparação da apresentação                                                                           X
Defesa do TCC                                                                                        X


7. REQUISITOS E APOIO INSTITUCIONAL

Para a execução bem-sucedida deste projeto, serão necessários os seguintes recursos e apoios:

Infraestrutura Computacional:
- Servidor com mínimo 32GB RAM e 8 cores para desenvolvimento
- Acesso a GPU NVIDIA com pelo menos 16GB VRAM para treinamento de modelos
- Conta em cloud provider (AWS/GCP/Azure) para testes de escalabilidade
- Licenças de software para ferramentas de desenvolvimento e análise

Acesso a Dados e APIs:
- Chave de API do Portal da Transparência com limite aumentado
- Acesso a datasets históricos para treinamento (2015-2024)
- Permissão para uso acadêmico dos dados públicos
- Datasets de validação com casos confirmados de irregularidades

Apoio Institucional do IFSULDEMINAS:
- Orientação acadêmica especializada continuada
- Acesso às bases de dados científicas (IEEE, ACM, Springer)
- Apoio para participação em eventos científicos
- Infraestrutura de laboratório quando necessário
- Possibilidade de bolsa de iniciação científica

Parcerias Estratégicas:
- Controladoria-Geral da União (CGU): Validação de metodologia e acesso a casos de estudo
- Tribunal de Contas da União (TCU): Expertise em auditoria e validação de resultados
- Transparência Brasil: Conhecimento de domínio e rede de contatos
- Laboratórios de IA de universidades parceiras: Colaboração técnica

Recursos Humanos:
- Orientador com expertise em IA e sistemas distribuídos
- Co-orientador da área de administração pública (desejável)
- Acesso a especialistas em transparência pública para validação
- Suporte técnico para infraestrutura quando necessário

Aspectos Éticos e Legais:
- Parecer do Comitê de Ética em Pesquisa (se aplicável)
- Termos de uso adequados para a plataforma
- Assessoria jurídica para questões de LGPD
- Seguro de responsabilidade civil para o projeto


8. DISSEMINAÇÃO DOS RESULTADOS

A estratégia de disseminação visa maximizar o impacto acadêmico e social do trabalho através de múltiplos canais:

Publicações Acadêmicas Planejadas:

Conferências Nacionais:
- Simpósio Brasileiro de Sistemas de Informação (SBSI): Artigo sobre arquitetura multi-agente
- Congresso da Sociedade Brasileira de Computação (CSBC): Track de IA aplicada ao setor público
- Workshop de Transparência em Sistemas (WTranS): Resultados de validação com usuários

Conferências Internacionais:
- International Conference on Electronic Government (EGOV): Full paper sobre o sistema completo
- International Conference on Digital Government Research (dg.o): Estudo de impacto social
- AAAI Conference on AI for Social Good: Aplicação de IA para transparência

Periódicos Alvo:
- Government Information Quarterly: Artigo sobre democratização do acesso via IA
- Revista de Administração Pública (RAP): Impacto no controle social
- Journal of Information Technology & Politics: Aspectos técnicos e políticos

Divulgação Técnica e Profissional:
- Publicação de série de artigos técnicos no Medium e Dev.to
- Palestras em meetups de Python, IA e Dados Abertos
- Webinars para comunidade de desenvolvedores cívicos
- Vídeos tutoriais no YouTube demonstrando o sistema
- Participação em podcasts sobre tecnologia e cidadania

Engajamento com Sociedade Civil:
- Workshops gratuitos para jornalistas investigativos
- Treinamento para ONGs de controle social
- Material didático para disciplinas de transparência pública
- Cartilhas para cidadãos sobre uso da ferramenta
- Hackathons focados em transparência usando a plataforma

Estratégia de Código Aberto:
- Repositório público no GitHub com documentação completa
- Licença permissiva (MIT ou Apache 2.0)
- Guias de contribuição para a comunidade
- Issues bem documentadas para novos contribuidores
- Exemplos de uso e casos de estudo

Plano de Comunicação:
- Website dedicado ao projeto com blog de atualizações
- Presença em redes sociais acadêmicas (ResearchGate, Academia.edu)
- Newsletter mensal sobre descobertas e melhorias
- Press releases para descobertas significativas
- Parcerias com veículos de mídia interessados


9. REFERÊNCIAS BIBLIOGRÁFICAS

BRASIL. Lei nº 12.527, de 18 de novembro de 2011. Regula o acesso a informações previsto no inciso XXXIII do art. 5º, no inciso II do § 3º do art. 37 e no § 2º do art. 216 da Constituição Federal. Diário Oficial da União, Brasília, DF, 18 nov. 2011.

BRASIL. Lei Complementar nº 131, de 27 de maio de 2009. Estabelece normas de finanças públicas voltadas para a responsabilidade na gestão fiscal. Diário Oficial da União, Brasília, DF, 28 mai. 2009.

BRASIL. Decreto nº 8.777, de 11 de maio de 2016. Institui a Política de Dados Abertos do Poder Executivo federal. Diário Oficial da União, Brasília, DF, 12 mai. 2016.

BROWN, T. et al. Language models are few-shot learners. In: Advances in neural information processing systems, v. 33, p. 1877-1901, 2020.

BUGARIN, M. S.; BUGARIN, B. F. Inteligência artificial no Tribunal de Contas da União (TCU): o caso Alice. Revista do TCU, n. 138, p. 28-35, 2017.

CHANDOLA, V.; BANERJEE, A.; KUMAR, V. Anomaly detection: A survey. ACM computing surveys (CSUR), v. 41, n. 3, p. 1-58, 2009.

CHEN, L.; RODRIGUEZ, M.; JOHNSON, A. OpenGov: A Platform for Automated Government Transparency. In: ACM Digital Government Research Conference, 2022.

CHEN, W. et al. Detecting corruption in public contracts using graph neural networks. Expert Systems with Applications, v. 195, 116587, 2022.

DEVLIN, J. et al. BERT: Pre-training of deep bidirectional transformers for language understanding. In: Proceedings of NAACL-HLT, p. 4171-4186, 2019.

EVANS, E. Domain-driven design: tackling complexity in the heart of software. Boston: Addison-Wesley Professional, 2003.

FAZEKAS, M.; KOCSIS, G. Uncovering high-level corruption: cross-national objective corruption risk indicators using public procurement data. British Journal of Political Science, v. 50, n. 1, p. 155-164, 2020.

FILGUEIRAS, F. Além da transparência: accountability e política da publicidade. Lua Nova: Revista de Cultura e Política, n. 84, p. 65-94, 2011.

FIQUEM SABENDO. Plataforma de acesso à informação pública. 2018. Disponível em: https://fiquemsabendo.com.br/. Acesso em: 15 jul. 2025.

GOODFELLOW, I.; BENGIO, Y.; COURVILLE, A. Deep learning. Cambridge: MIT press, 2016.

HEVNER, A. R. et al. Design science in information systems research. MIS quarterly, v. 28, n. 1, p. 75-105, 2004.

JANSSEN, M.; CHARALABIDIS, Y.; ZUIDERWIJK, A. Benefits, adoption barriers and myths of open data and open government. Information systems management, v. 29, n. 4, p. 258-268, 2012.

JURAFSKY, D.; MARTIN, J. H. Speech and language processing. 3rd ed. Draft. Stanford University, 2023.

LIU, F. T.; TING, K. M.; ZHOU, Z. H. Isolation forest. In: 2008 eighth ieee international conference on data mining. IEEE, p. 413-422, 2008.

MICHENER, G.; BERSCH, K. Identifying transparency. Information Polity, v. 18, n. 3, p. 233-242, 2013.

OLIVEIRA, J. S. Desenvolvimento de chatbot para acesso a informações públicas. 2020. Dissertação (Mestrado em Ciência da Computação) – Universidade Federal de Minas Gerais, Belo Horizonte, 2020.

OPEN KNOWLEDGE FOUNDATION. Open Data Handbook. 2015. Disponível em: http://opendatahandbook.org/. Acesso em: 15 jul. 2025.

PINHO, J. A. G.; SACRAMENTO, A. R. S. Accountability: já podemos traduzi-la para o português? Revista de Administração Pública, v. 43, n. 6, p. 1343-1368, 2009.

POSSAMAI, A. J.; GONZATTI, R. Dados abertos governamentais: iniciativas e desafios na abertura de dados no Brasil e outras esferas internacionais. Revista Eletrônica Internacional de Economia Política da Informação, da Comunicação e da Cultura, v. 22, n. 2, p. 114-130, 2020.

RUSSELL, S.; NORVIG, P. Artificial intelligence: a modern approach. 4th ed. Pearson, 2021.

SCHÖLKOPF, B. et al. Estimating the support of a high-dimensional distribution. Neural computation, v. 13, n. 7, p. 1443-1471, 2001.

SCHREYER, M. et al. Detection of anomalies in large scale accounting data using deep autoencoder networks. arXiv preprint arXiv:1709.05254, 2017.

SERENATA DE AMOR. Operação Serenata de Amor. 2016. Disponível em: https://serenata.ai/. Acesso em: 15 jul. 2025.

SILVA, A. H. Cidadão.AI: Sistema Multi-Agente de Inteligência Artificial para Análise de Transparência Pública Brasileira. 2024. Documentação Técnica Completa - Sistema de IA, Hugging Face Spaces, 2024. Disponível em: https://huggingface.co/spaces/neural-thinker/cidadao.ai.

SILVA, A. H. Relatório Técnico Executivo - Cidadão.AI. Documentação técnica, 2025. 

SILVA, R. M. et al. Big data analytics for government transparency: A systematic mapping study. Government Information Quarterly, v. 38, n. 3, 2021.

SOUZA, F.; NOGUEIRA, R.; LOTUFO, R. BERTimbau: Pretrained BERT models for Brazilian Portuguese. In: Brazilian Conference on Intelligent Systems. Springer, p. 403-417, 2020.

WOOLDRIDGE, M. An Introduction to MultiAgent Systems. 2nd ed. Chichester: John Wiley & Sons, 2009.


Muzambinho, ___ de ________ de 2025.


---

Assinatura:

_________________________________
Anderson Henrique da Silva
Autor


_________________________________
[Nome do Orientador]
Orientador(a)