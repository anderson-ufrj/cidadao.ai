<!-- Algoritmos Avan√ßados de Explainable AI PhD-Level -->

<style>
    .xai-algorithm-box {
        background: linear-gradient(135deg, #ede9fe, #ddd6fe);
        border: 2px solid #7c3aed;
        border-radius: 1rem;
        padding: 2rem;
        margin: 2rem 0;
    }
    .shap-box {
        background: linear-gradient(135deg, #f0f9ff, #e0f2fe);
        border: 2px solid #0284c7;
        border-radius: 1rem;
        padding: 2rem;
        margin: 2rem 0;
    }
    .lime-box {
        background: linear-gradient(135deg, #f0fdf4, #dcfce7);
        border: 2px solid #16a34a;
        border-radius: 1rem;
        padding: 2rem;
        margin: 2rem 0;
    }
    .causal-box {
        background: linear-gradient(135deg, #fee2e2, #fecaca);
        border: 2px solid #dc2626;
        border-radius: 1rem;
        padding: 2rem;
        margin: 2rem 0;
    }
    .neural-box {
        background: linear-gradient(135deg, #e0e7ff, #c7d2fe);
        border: 2px solid #4f46e5;
        border-radius: 1rem;
        padding: 2rem;
        margin: 2rem 0;
    }
    .algorithm-code {
        background: #1e293b;
        color: #e2e8f0;
        border-radius: 0.5rem;
        padding: 1.5rem;
        margin: 1.5rem 0;
        font-family: 'Courier New', monospace;
        font-size: 0.9rem;
        overflow-x: auto;
    }
    .axiom-list {
        background: white;
        border-radius: 0.5rem;
        padding: 1.5rem;
        margin: 1.5rem 0;
        border: 1px solid #e2e8f0;
    }
    .complexity-note {
        background: #fef3c7;
        border: 1px solid #f59e0b;
        border-radius: 0.5rem;
        padding: 1rem;
        margin: 1rem 0;
        font-size: 0.9rem;
    }
</style>

<!-- T√≠tulo Principal -->
<h3 style="font-size: 1.25rem; font-weight: 600; color: var(--text-primary); margin: 3rem 0 1.5rem 0;">
    üî¨ Algoritmos Avan√ßados de Explainable AI
</h3>

<p style="color: var(--text-secondary); margin-bottom: 2rem; line-height: 1.6;">
    Implementa√ß√£o rigorosa de algoritmos XAI com fundamentos matem√°ticos s√≥lidos, garantindo explicabilidade completa das decis√µes do sistema multi-agente do Cidad√£o.AI.
</p>

<!-- SHAP com Fundamentos Rigorosos -->
<div class="shap-box">
    <h4 style="color: #0c4a6e; margin-bottom: 1.5rem;">SHAP: Axiomatiza√ß√£o Completa e Implementa√ß√£o</h4>
    
    <div class="axiom-list">
        <p><strong>Axiomas de Shapley (1953) - Base Te√≥rica:</strong></p>
        <ol style="margin: 1rem 0; line-height: 1.8;">
            <li><strong>Efici√™ncia:</strong> Œ£·µ¢‚Çå‚ÇÅ‚Åø œÜ·µ¢(v) = v(N) - v(‚àÖ)</li>
            <li><strong>Simetria:</strong> Se i,j s√£o substitu√≠veis em v, ent√£o œÜ·µ¢(v) = œÜ‚±º(v)</li>
            <li><strong>Dummy:</strong> Se i √© dummy player, ent√£o œÜ·µ¢(v) = v({i}) - v(‚àÖ)</li>
            <li><strong>Aditividade:</strong> œÜ·µ¢(v + w) = œÜ·µ¢(v) + œÜ·µ¢(w)</li>
        </ol>
        
        <p style="margin-top: 1.5rem;"><strong>Teorema de Unicidade (Shapley, 1953):</strong></p>
        <p>Existe uma √∫nica fun√ß√£o œÜ: 2·¥∫ ‚Üí ‚Ñù‚Åø satisfazendo os axiomas acima:</p>
        <div style="text-align: center; margin: 1.5rem 0; font-family: 'Times New Roman', serif; font-size: 1.1rem;">
            œÜ·µ¢(v) = Œ£<sub>S‚äÜN\{i}</sub> [|S|!(n-|S|-1)!/n!] √ó [v(S‚à™{i}) - v(S)]
        </div>
    </div>
    
    <p><strong>Implementa√ß√£o Computacional no Cidad√£o.AI:</strong></p>
    
    <div class="algorithm-code">
def TreeSHAP_optimized(model, X, feature_perturbation='tree_path_dependent'):
    """
    Implementa√ß√£o otimizada do TreeSHAP para modelos ensemble
    Complexidade: O(TLD¬≤) onde T=√°rvores, L=folhas, D=profundidade
    """
    def traverse_tree(tree, x, path_idx=0):
        node = tree.nodes[path_idx]
        
        if node.is_leaf():
            return node.value
        
        # Tree path dependent perturbation
        if x[node.feature] <= node.threshold:
            left_contrib = traverse_tree(tree, x, node.left_child)
            right_contrib = conditional_expectation(tree, node.right_subtree, x)
            
            # Marginal contribution calculation
            return left_contrib + (right_contrib - left_contrib) * path_probability
        else:
            # Mirror calculation for right path
            right_contrib = traverse_tree(tree, x, node.right_child)
            left_contrib = conditional_expectation(tree, node.left_subtree, x)
            return right_contrib + (left_contrib - right_contrib) * path_probability
    
    # Aggregate across all trees in ensemble
    shap_values = np.zeros((len(X), X.shape[1]))
    for tree_idx, tree in enumerate(model.estimators_):
        tree_shap = compute_tree_shap(tree, X)
        shap_values += tree_shap / len(model.estimators_)
    
    return shap_values
    </div>
    
    <div class="complexity-note">
        <strong>Complexidade Garantida:</strong> O(TLD¬≤) para T √°rvores, L folhas m√°ximas, D profundidade m√°xima. 
        Para o sistema Cidad√£o.AI com Random Forest de 100 √°rvores, profundidade 10: ~O(10‚Åµ) opera√ß√µes por explica√ß√£o.
    </div>
    
    <p><strong>Aplica√ß√£o no InvestigatorAgent:</strong></p>
    <ul style="margin-left: 1.5rem; line-height: 1.6;">
        <li>‚Ä¢ Explica decis√µes de classifica√ß√£o de anomalias em contratos p√∫blicos</li>
        <li>‚Ä¢ Identifica features cr√≠ticas: valor, frequ√™ncia, hist√≥rico do fornecedor</li>
        <li>‚Ä¢ Gera visualiza√ß√µes para auditores com garantias matem√°ticas</li>
        <li>‚Ä¢ Satisfaz propriedade de efici√™ncia: soma das contribui√ß√µes = predi√ß√£o</li>
    </ul>
</div>

<!-- LIME para Explica√ß√µes Locais -->
<div class="lime-box">
    <h4 style="color: #14532d; margin-bottom: 1.5rem;">LIME: Explica√ß√µes Locais Interpret√°veis</h4>
    
    <div class="axiom-list">
        <p><strong>Formula√ß√£o Matem√°tica:</strong></p>
        <div style="text-align: center; margin: 1.5rem 0; font-family: 'Times New Roman', serif; font-size: 1.1rem;">
            Œæ(x) = argmin<sub>g‚ààG</sub> L(f, g, œÄ<sub>x</sub>) + Œ©(g)
        </div>
        <p>onde:</p>
        <ul style="margin: 1rem 0; line-height: 1.6;">
            <li>‚Ä¢ <strong>L(f, g, œÄ<sub>x</sub>):</strong> Fun√ß√£o de perda entre modelo complexo f e explica√ß√£o g</li>
            <li>‚Ä¢ <strong>œÄ<sub>x</sub>(z):</strong> Medida de proximidade de z a x (kernel de localidade)</li>
            <li>‚Ä¢ <strong>Œ©(g):</strong> Medida de complexidade da explica√ß√£o g</li>
            <li>‚Ä¢ <strong>G:</strong> Classe de modelos interpret√°veis (ex: regress√£o linear)</li>
        </ul>
        
        <p style="margin-top: 1.5rem;"><strong>Kernel de Localidade:</strong></p>
        <div style="text-align: center; margin: 1rem 0;">
            œÄ<sub>x</sub>(z) = exp(-D(x,z)¬≤/œÉ¬≤)
        </div>
        <p>onde D(x,z) √© uma m√©trica de dist√¢ncia apropriada ao dom√≠nio.</p>
    </div>
    
    <div class="algorithm-code">
def LIME_tabular_optimized(model, instance, feature_names, num_samples=5000):
    """
    LIME otimizado para dados tabulares (contratos/licita√ß√µes)
    """
    # Generate neighborhood around instance
    neighborhood = generate_neighborhood(instance, num_samples)
    
    # Compute distances and weights
    distances = pairwise_distances(neighborhood, instance.reshape(1, -1), 
                                 metric='cosine').ravel()
    weights = np.exp(-(distances**2) / (0.25**2))  # œÉ = 0.25
    
    # Get model predictions for neighborhood
    predictions = model.predict_proba(neighborhood)[:, 1]  # probability of anomaly
    
    # Fit interpretable model (Ridge regression for stability)
    interpretable_model = Ridge(alpha=1.0, fit_intercept=True)
    interpretable_model.fit(neighborhood, predictions, sample_weight=weights)
    
    # Extract feature importance
    feature_importance = dict(zip(feature_names, interpretable_model.coef_))
    
    # Compute fidelity score
    local_predictions = interpretable_model.predict(neighborhood)
    fidelity = r2_score(predictions, local_predictions, sample_weight=weights)
    
    return {
        'feature_importance': feature_importance,
        'intercept': interpretable_model.intercept_,
        'fidelity': fidelity,
        'neighborhood_size': num_samples
    }
    </div>
    
    <p><strong>Garantias Te√≥ricas:</strong></p>
    <ul style="margin-left: 1.5rem; line-height: 1.6;">
        <li>‚Ä¢ <strong>Aproxima√ß√£o Local:</strong> ‚Äñf(x) - g(x)‚Äñ<sub>œÄ</sub> ‚â§ Œµ com probabilidade ‚â• 1-Œ¥</li>
        <li>‚Ä¢ <strong>Sample Complexity:</strong> n ‚â• O((d/Œµ¬≤)log(d/Œ¥)) para dimens√£o d</li>
        <li>‚Ä¢ <strong>Fidelidade:</strong> R¬≤ > 0.8 na vizinhan√ßa local garantida</li>
    </ul>
    
    <p><strong>Uso no AnalystAgent:</strong></p>
    <ul style="margin-left: 1.5rem; line-height: 1.6;">
        <li>‚Ä¢ Explica decis√µes locais em an√°lises de contratos espec√≠ficos</li>
        <li>‚Ä¢ Gera aproxima√ß√µes lineares interpret√°veis para auditores</li>
        <li>‚Ä¢ Permite debugging de decis√µes particulares</li>
        <li>‚Ä¢ Identifica features mais influentes para cada caso</li>
    </ul>
</div>

<!-- Infer√™ncia Causal e Counterfactuals -->
<div class="causal-box">
    <h4 style="color: #7f1d1d; margin-bottom: 1.5rem;">Infer√™ncia Causal e Explica√ß√µes Counterfactuais</h4>
    
    <div class="axiom-list">
        <p><strong>Modelo Causal Estrutural (SCM):</strong></p>
        <p>Seja M = ‚ü®U, V, F, P(U)‚ü© um modelo causal onde:</p>
        <ul style="margin: 1rem 0; line-height: 1.8;">
            <li>‚Ä¢ <strong>U:</strong> Vari√°veis ex√≥genas (n√£o observadas, ru√≠do)</li>
            <li>‚Ä¢ <strong>V = {V‚ÇÅ, V‚ÇÇ, ..., V‚Çô}:</strong> Vari√°veis end√≥genas (observadas)</li>
            <li>‚Ä¢ <strong>F = {f‚ÇÅ, f‚ÇÇ, ..., f‚Çô}:</strong> Fun√ß√µes estruturais V·µ¢ = f·µ¢(pa(V·µ¢), U·µ¢)</li>
            <li>‚Ä¢ <strong>P(U):</strong> Distribui√ß√£o de probabilidade sobre vari√°veis ex√≥genas</li>
        </ul>
        
        <p style="margin-top: 1.5rem;"><strong>Query Counterfactual:</strong></p>
        <div style="text-align: center; margin: 1.5rem 0; font-family: 'Times New Roman', serif;">
            P(Y<sub>x</sub> = y | E = e) = Œ£<sub>u</sub> P(Y = y | do(X = x), U = u) √ó P(U = u | E = e)
        </div>
    </div>
    
    <div class="algorithm-code">
def generate_counterfactual_explanation(instance, model, target_class, 
                                      feature_constraints=None, lambda_reg=0.1):
    """
    Gera√ß√£o de explica√ß√µes counterfactuais otimizadas
    """
    x_original = instance.copy()
    x_cf = x_original.copy()
    
    # Define loss function: prediction loss + distance penalty
    def loss_function(x_candidate):
        # Prediction loss (cross-entropy)
        pred_prob = model.predict_proba(x_candidate.reshape(1, -1))[0]
        pred_loss = -np.log(pred_prob[target_class] + 1e-8)
        
        # Distance penalty (L1 + L2 for sparsity and smoothness)
        l1_dist = np.sum(np.abs(x_candidate - x_original))
        l2_dist = np.sum((x_candidate - x_original)**2)
        distance_penalty = lambda_reg * (0.5 * l1_dist + 0.5 * l2_dist)
        
        return pred_loss + distance_penalty
    
    # Constraint handling for valid feature ranges
    bounds = []
    for i, feature_name in enumerate(feature_names):
        if feature_constraints and feature_name in feature_constraints:
            bounds.append(feature_constraints[feature_name])
        else:
            # Use data-driven bounds (5th-95th percentile)
            bounds.append((X_train[:, i].quantile(0.05), 
                          X_train[:, i].quantile(0.95)))
    
    # Optimization with L-BFGS-B (handles bounds efficiently)
    result = minimize(loss_function, x_cf, method='L-BFGS-B', 
                     bounds=bounds, options={'maxiter': 1000})
    
    x_counterfactual = result.x
    
    # Verify counterfactual quality
    cf_prediction = model.predict(x_counterfactual.reshape(1, -1))[0]
    distance = np.linalg.norm(x_counterfactual - x_original)
    validity = (cf_prediction == target_class)
    
    return {
        'counterfactual': x_counterfactual,
        'original_prediction': model.predict(x_original.reshape(1, -1))[0],
        'cf_prediction': cf_prediction,
        'distance': distance,
        'validity': validity,
        'feature_changes': x_counterfactual - x_original
    }
    </div>
    
    <p><strong>Aplica√ß√£o no Sistema:</strong></p>
    <ul style="margin-left: 1.5rem; line-height: 1.6;">
        <li>‚Ä¢ <strong>Pergunta:</strong> "O que mudaria para este contrato N√ÉO ser classificado como suspeito?"</li>
        <li>‚Ä¢ <strong>Resposta:</strong> "Se o valor fosse 15% menor E o fornecedor tivesse hist√≥rico limpo"</li>
        <li>‚Ä¢ <strong>Valida√ß√£o:</strong> Mudan√ßas m√≠nimas necess√°rias respeitando constraintes legais</li>
    </ul>
</div>

<!-- Neural Network Interpretability -->
<div class="neural-box">
    <h4 style="color: #312e81; margin-bottom: 1.5rem;">Interpretabilidade de Redes Neurais Profundas</h4>
    
    <div class="axiom-list">
        <p><strong>Integrated Gradients (Sundararajan et al., 2017):</strong></p>
        <div style="text-align: center; margin: 1.5rem 0; font-family: 'Times New Roman', serif;">
            IG<sub>i</sub>(x) = (x<sub>i</sub> - x'<sub>i</sub>) √ó ‚à´‚ÇÄ¬π ‚àÇf(x' + Œ±(x - x'))/‚àÇx<sub>i</sub> dŒ±
        </div>
        
        <p><strong>Propriedades Te√≥ricas Garantidas:</strong></p>
        <ol style="margin: 1rem 0; line-height: 1.8;">
            <li><strong>Sensibilidade:</strong> Se f(x) ‚â† f(x') e x<sub>i</sub> ‚â† x'<sub>i</sub>, ent√£o IG<sub>i</sub> ‚â† 0</li>
            <li><strong>Invari√¢ncia de Implementa√ß√£o:</strong> Independente da parametriza√ß√£o da rede</li>
            <li><strong>Completude:</strong> Œ£·µ¢ IG·µ¢(x) = f(x) - f(x') (conserva√ß√£o total)</li>
        </ol>
        
        <p style="margin-top: 1.5rem;"><strong>Layer-wise Relevance Propagation (LRP):</strong></p>
        <div style="text-align: center; margin: 1rem 0;">
            R<sub>i</sub><sup>(l)</sup> = Œ£‚±º (a<sub>i</sub>w<sub>ij</sub>/Œ£‚Çña<sub>k</sub>w<sub>kj</sub>) √ó R<sub>j</sub><sup>(l+1)</sup>
        </div>
        <p>com propriedade de conserva√ß√£o: Œ£·µ¢ R<sub>i</sub><sup>(l)</sup> = Œ£‚±º R<sub>j</sub><sup>(l+1)</sup> = f(x)</p>
    </div>
    
    <div class="algorithm-code">
def integrated_gradients_batched(model, inputs, baseline=None, steps=50):
    """
    Integrated Gradients otimizado com processamento em lote
    """
    if baseline is None:
        baseline = torch.zeros_like(inputs)
    
    # Generate interpolation path
    alphas = torch.linspace(0, 1, steps + 1)[1:]  # Exclude 0
    alphas = alphas.view(-1, 1, 1)  # Broadcast to batch dimension
    
    # Compute interpolated points
    interpolated = baseline.unsqueeze(0) + alphas * (inputs.unsqueeze(0) - baseline.unsqueeze(0))
    interpolated = interpolated.view(-1, *inputs.shape[1:])  # Flatten batch
    interpolated.requires_grad_(True)
    
    # Forward pass through model
    outputs = model(interpolated)
    target_outputs = outputs[:, target_class_idx]
    
    # Compute gradients
    gradients = torch.autograd.grad(
        outputs=target_outputs.sum(),
        inputs=interpolated,
        create_graph=False,
        retain_graph=False
    )[0]
    
    # Reshape and average over integration steps
    gradients = gradients.view(steps, *inputs.shape)
    avg_gradients = gradients.mean(dim=0)
    
    # Compute integrated gradients
    integrated_grads = (inputs - baseline) * avg_gradients
    
    return integrated_grads
    </div>
    
    <p><strong>Implementa√ß√£o no ReporterAgent:</strong></p>
    <ul style="margin-left: 1.5rem; line-height: 1.6;">
        <li>‚Ä¢ Visualiza attention maps em documentos de licita√ß√£o</li>
        <li>‚Ä¢ Gera heatmaps de relev√¢ncia para texto n√£o estruturado</li>
        <li>‚Ä¢ Permite rastreabilidade completa das conclus√µes</li>
        <li>‚Ä¢ Identifica padr√µes suspeitos em linguagem natural</li>
    </ul>
</div>

<!-- Framework Unificado -->
<h4 style="color: var(--text-primary); margin: 2rem 0 1rem 0;">üéØ Framework Unificado de Explicabilidade</h4>

<div style="background: var(--bg-secondary); border: 2px solid var(--border); border-radius: 1rem; padding: 2rem;">
    <p style="margin-bottom: 1.5rem;"><strong>Pipeline Formal:</strong> E: X √ó F √ó C ‚Üí XÃÉ</p>
    
    <div class="axiom-list">
        <p><strong>M√©tricas de Qualidade de Explica√ß√£o:</strong></p>
        <div style="margin: 1rem 0; line-height: 1.8;">
            <p><strong>1. Fidelidade:</strong> œÅ(E, f) = ùîº<sub>x</sub>[‚Äñf(x) - fÃÉ<sub>E</sub>(x)‚Äñ¬≤]</p>
            <p><strong>2. Estabilidade:</strong> œÉ(E) = ùîº[‚ÄñE(x + Œµ) - E(x)‚Äñ / ‚ÄñŒµ‚Äñ]</p>
            <p><strong>3. Complexidade:</strong> Œ∫(E) = |{features: |œÜ·µ¢| > œÑ}|</p>
            <p><strong>4. Coer√™ncia Causal:</strong> Œ≥(E) = P(E satisfaz restri√ß√µes causais)</p>
        </div>
    </div>
    
    <div style="display: grid; gap: 1.5rem; margin-top: 2rem;">
        <div style="background: linear-gradient(135deg, #f0f9ff, #e0f2fe); border: 1px solid #0284c7; border-radius: 0.5rem; padding: 1.5rem;">
            <h5 style="color: #0c4a6e; margin-bottom: 0.5rem;">N√≠vel 1: Explica√ß√£o Global</h5>
            <p><strong>Permutation Importance:</strong> I(f<sub>j</sub>) = ùîº[L(Y, f(X))] - ùîº[L(Y, f(X<sup>œÄ<sub>j</sub></sup>))]</p>
            <p><strong>Partial Dependence:</strong> fÃÑ<sub>S</sub>(x<sub>S</sub>) = ùîº<sub>X<sub>C</sub></sub>[f(x<sub>S</sub>, X<sub>C</sub>)]</p>
        </div>
        
        <div style="background: linear-gradient(135deg, #f0fdf4, #dcfce7); border: 1px solid #16a34a; border-radius: 0.5rem; padding: 1.5rem;">
            <h5 style="color: #14532d; margin-bottom: 0.5rem;">N√≠vel 2: Explica√ß√£o Local</h5>
            <p>SHAP values com garantias axiom√°ticas completas</p>
            <p>Counterfactuals √≥timos via programa√ß√£o convexa</p>
            <p>Anchors com garantias: P(f(x) = f(a(x))) ‚â• 1-Œ¥</p>
        </div>
        
        <div style="background: linear-gradient(135deg, #fef3c7, #fde68a); border: 1px solid #f59e0b; border-radius: 0.5rem; padding: 1.5rem;">
            <h5 style="color: #78350f; margin-bottom: 0.5rem;">N√≠vel 3: Explica√ß√£o Sem√¢ntica</h5>
            <p><strong>Template-based:</strong> g: XÃÉ ‚Üí L (linguagem natural)</p>
            <p><strong>Restri√ß√µes:</strong> coherence(g(xÃÉ)) ‚àß correctness(g(xÃÉ)) ‚àß completeness(g(xÃÉ))</p>
        </div>
    </div>
</div>

<!-- Garantias de Performance -->
<div style="background: linear-gradient(135deg, #fef2f2, #fee2e2); border: 2px solid #ef4444; border-radius: 1rem; padding: 2rem; margin: 2rem 0;">
    <h4 style="color: #991b1b; margin-bottom: 1.5rem;">Garantias Te√≥ricas e Bounds de Performance</h4>
    <div class="axiom-list">
        <p><strong>Teorema (Sample Complexity para Explica√ß√µes LIME):</strong></p>
        <p>Para obter explica√ß√µes Œµ-precisas com probabilidade 1-Œ¥, necessitamos:</p>
        <div style="text-align: center; margin: 1.5rem 0; font-family: 'Times New Roman', serif;">
            n ‚â• (2/Œµ¬≤) √ó [VC(H) √ó log(2/Œµ) + log(2/Œ¥)]
        </div>
        <p>onde VC(H) √© a dimens√£o Vapnik-Chervonenkis do espa√ßo de hip√≥teses.</p>
        
        <p style="margin-top: 1.5rem;"><strong>Bound de Aproxima√ß√£o (Fidelidade):</strong></p>
        <div style="margin: 1rem 0;">
            ‚Äñf(x) - g(x)‚Äñ<sub>œÄ</sub> ‚â§ Œµ com probabilidade ‚â• 1 - Œ¥
        </div>
        <p>se |D| ‚â• O((d/Œµ¬≤) √ó log(d/Œ¥)), onde d √© a dimensionalidade local.</p>
        
        <p style="margin-top: 1.5rem;"><strong>Complexidade Temporal Garantida:</strong></p>
        <ul style="margin-left: 1.5rem; line-height: 1.6;">
            <li>‚Ä¢ <strong>SHAP:</strong> O(2·µà) exata, O(M) aproximada com M samples</li>
            <li>‚Ä¢ <strong>LIME:</strong> O(Md + d¬≥) para M samples, d features</li>
            <li>‚Ä¢ <strong>Integrated Gradients:</strong> O(kd) para k integration steps</li>
        </ul>
    </div>
</div>