#!/usr/bin/env python3
"""
ğŸ¤– CidadÃ£oGPT - DemonstraÃ§Ã£o Interativa

Script de demonstraÃ§Ã£o do modelo especializado em transparÃªncia pÃºblica.
Inspirado no Kimi K2, mas focado em anÃ¡lise governamental brasileira.
"""

import asyncio
import json
import sys
from pathlib import Path
import logging
from typing import Dict, Any
import time
from datetime import datetime

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

# Importar componentes do modelo
try:
    from src.ml.cidadao_model import create_cidadao_model, CidadaoGPTForTransparency
    from src.ml.model_api import CidadaoGPTManager, TransparencyAnalysisRequest
    from src.ml.transparency_benchmark import run_transparency_benchmark, BenchmarkConfig
    from src.ml.training_pipeline import create_training_pipeline, TrainingConfig
    from src.ml.data_pipeline import run_data_pipeline, DataPipelineConfig
except ImportError as e:
    logger.error(f"âŒ Erro ao importar mÃ³dulos: {e}")
    logger.error("ğŸ’¡ Certifique-se de que estÃ¡ no diretÃ³rio raiz do projeto")
    sys.exit(1)


class CidadaoGPTDemo:
    """DemonstraÃ§Ã£o interativa do CidadÃ£oGPT"""
    
    def __init__(self):
        self.model = None
        self.manager = None
        self.demo_data = self._load_demo_data()
        
    def _load_demo_data(self) -> Dict[str, Any]:
        """Carregar dados de demonstraÃ§Ã£o"""
        
        return {
            "contratos_exemplo": [
                {
                    "id": "normal_001",
                    "titulo": "ğŸ“‹ Contrato Normal - AquisiÃ§Ã£o de Material de EscritÃ³rio",
                    "texto": """PregÃ£o eletrÃ´nico nÂº 001/2024 para aquisiÃ§Ã£o de material de escritÃ³rio 
                    no valor de R$ 75.000,00. Fornecedor: Papelaria Central LTDA, CNPJ regular, 
                    processo licitatÃ³rio conduzido conforme Lei 14.133/2021, com ampla participaÃ§Ã£o 
                    e documentaÃ§Ã£o completa.""",
                    "esperado": "Normal - Baixo Risco"
                },
                {
                    "id": "suspeito_001", 
                    "titulo": "âš ï¸ Contrato Suspeito - Obra com Prazo Apertado",
                    "texto": """ContrataÃ§Ã£o de obra de pavimentaÃ§Ã£o no valor de R$ 5.000.000,00 
                    com prazo de licitaÃ§Ã£o reduzido para 5 dias. Apenas duas empresas participaram, 
                    sendo uma delas recÃ©m-constituÃ­da. Processo tem justificativa de urgÃªncia 
                    questionÃ¡vel.""",
                    "esperado": "Suspeito - MÃ©dio Risco"
                },
                {
                    "id": "anomalo_001",
                    "titulo": "ğŸš¨ Contrato AnÃ´malo - Dispensa Irregular",
                    "texto": """Contrato emergencial de R$ 25.000.000,00 para 'consultoria em gestÃ£o' 
                    dispensando licitaÃ§Ã£o. Empresa contratada nÃ£o possui funcionÃ¡rios registrados 
                    e pertence ao cÃ´njuge do secretÃ¡rio responsÃ¡vel. Pagamento integral antecipado 
                    sem garantias.""",
                    "esperado": "AnÃ´malo - Alto Risco"
                },
                {
                    "id": "complexo_001",
                    "titulo": "ğŸ—ï¸ Contrato Complexo - ConstruÃ§Ã£o Hospitalar",
                    "texto": """ConcorrÃªncia pÃºblica para construÃ§Ã£o de hospital no valor de 
                    R$ 150.000.000,00. Projeto bÃ¡sico incompleto, histÃ³rico de aditivos contratuais 
                    excessivos em obras similares do mesmo Ã³rgÃ£o. Empresa vencedora tem capacidade 
                    tÃ©cnica questionÃ¡vel para projeto desta magnitude.""",
                    "esperado": "Alto Risco Financeiro"
                }
            ],
            
            "cenarios_chat": [
                {
                    "pergunta": "O que Ã© um superfaturamento e como identificÃ¡-lo?",
                    "contexto": "Educacional"
                },
                {
                    "pergunta": "Analise este contrato: AquisiÃ§Ã£o de equipamentos por R$ 10 milhÃµes sem licitaÃ§Ã£o.",
                    "contexto": "AnÃ¡lise direta"
                },
                {
                    "pergunta": "Quais sÃ£o os principais indicadores de corrupÃ§Ã£o em licitaÃ§Ãµes?",
                    "contexto": "Consultoria"
                }
            ]
        }

    async def run_demo(self):
        """Executar demonstraÃ§Ã£o completa"""
        
        print("\n" + "="*70)
        print("ğŸ¤– CIDADÃƒOGPT - DEMONSTRAÃ‡ÃƒO INTERATIVA")
        print("Modelo de IA Especializado em TransparÃªncia PÃºblica Brasileira")
        print("Inspirado no Kimi K2, otimizado para anÃ¡lise governamental")
        print("="*70)
        
        await self._init_model()
        
        while True:
            try:
                choice = self._show_main_menu()
                
                if choice == "1":
                    await self._demo_analysis()
                elif choice == "2":
                    await self._demo_chat()
                elif choice == "3":
                    await self._demo_batch_analysis()
                elif choice == "4":
                    await self._demo_benchmark()
                elif choice == "5":
                    await self._demo_training()
                elif choice == "6":
                    self._show_model_info()
                elif choice == "0":
                    print("\nğŸ‘‹ Obrigado por usar o CidadÃ£oGPT!")
                    break
                else:
                    print("âŒ OpÃ§Ã£o invÃ¡lida. Tente novamente.")
                    
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ DemonstraÃ§Ã£o interrompida. AtÃ© logo!")
                break
            except Exception as e:
                logger.error(f"âŒ Erro na demonstraÃ§Ã£o: {e}")
                print(f"âŒ Erro: {e}")

    async def _init_model(self):
        """Inicializar modelo"""
        
        print("\nğŸ”„ Inicializando CidadÃ£oGPT...")
        
        try:
            # Criar modelo
            self.model = create_cidadao_model(
                specialized_tasks=["all"],
                model_size="medium"
            )
            
            # Criar manager
            self.manager = CidadaoGPTManager()
            self.manager.model = self.model
            self.manager.loaded = True
            
            # Contar parÃ¢metros
            total_params = sum(p.numel() for p in self.model.parameters())
            
            print(f"âœ… Modelo carregado com sucesso!")
            print(f"ğŸ“Š ParÃ¢metros: {total_params:,}")
            print(f"ğŸ¯ Tarefas especializadas: Anomalias, Risco Financeiro, Conformidade Legal")
            
        except Exception as e:
            logger.error(f"âŒ Erro ao carregar modelo: {e}")
            print(f"âŒ Erro: {e}")
            sys.exit(1)

    def _show_main_menu(self) -> str:
        """Mostrar menu principal"""
        
        print("\n" + "="*50)
        print("ğŸ“‹ MENU PRINCIPAL")
        print("="*50)
        print("1. ğŸ” DemonstraÃ§Ã£o de AnÃ¡lise de TransparÃªncia")
        print("2. ğŸ’¬ Chat Interativo com CidadÃ£oGPT") 
        print("3. ğŸ“Š AnÃ¡lise em Lote")
        print("4. ğŸ† Benchmark de Performance")
        print("5. ğŸ“ DemonstraÃ§Ã£o de Treinamento")
        print("6. â„¹ï¸ InformaÃ§Ãµes do Modelo")
        print("0. ğŸšª Sair")
        print("="*50)
        
        return input("ğŸ¤– Escolha uma opÃ§Ã£o: ").strip()

    async def _demo_analysis(self):
        """DemonstraÃ§Ã£o de anÃ¡lise de transparÃªncia"""
        
        print("\n" + "="*60)
        print("ğŸ” DEMONSTRAÃ‡ÃƒO - ANÃLISE DE TRANSPARÃŠNCIA")
        print("="*60)
        
        print("\nğŸ“‹ Contratos disponÃ­veis para anÃ¡lise:")
        
        for i, contrato in enumerate(self.demo_data["contratos_exemplo"], 1):
            print(f"{i}. {contrato['titulo']}")
        
        print("5. âœï¸ Inserir texto personalizado")
        
        choice = input("\nğŸ¤– Escolha um contrato (1-5): ").strip()
        
        try:
            if choice in ["1", "2", "3", "4"]:
                contrato = self.demo_data["contratos_exemplo"][int(choice) - 1]
                texto = contrato["texto"]
                esperado = contrato["esperado"]
                
                print(f"\nğŸ“„ Analisando: {contrato['titulo']}")
                print(f"ğŸ“ Resultado esperado: {esperado}")
                
            elif choice == "5":
                texto = input("\nğŸ“ Digite o texto para anÃ¡lise: ").strip()
                if not texto:
                    print("âŒ Texto vazio. Voltando ao menu.")
                    return
                esperado = "NÃ£o definido"
                
            else:
                print("âŒ OpÃ§Ã£o invÃ¡lida.")
                return
            
            # Executar anÃ¡lise
            print("\nğŸ”„ Executando anÃ¡lise...")
            start_time = time.time()
            
            request = TransparencyAnalysisRequest(
                text=texto,
                analysis_type="complete",
                include_explanation=True
            )
            
            result = await self.manager.analyze_transparency(request)
            
            processing_time = time.time() - start_time
            
            # Mostrar resultados
            self._display_analysis_results(result, processing_time, esperado)
            
        except Exception as e:
            logger.error(f"âŒ Erro na anÃ¡lise: {e}")
            print(f"âŒ Erro: {e}")

    def _display_analysis_results(self, result, processing_time: float, esperado: str):
        """Exibir resultados da anÃ¡lise"""
        
        print("\n" + "="*60)
        print("ğŸ“Š RESULTADOS DA ANÃLISE")
        print("="*60)
        
        # Resumo executivo
        summary = result.executive_summary
        print(f"\nğŸ¯ RESUMO EXECUTIVO")
        print(f"   â€¢ NÃ­vel de Risco: {summary['overall_risk']}")
        print(f"   â€¢ Alerta: {summary['alert_level']}")
        print(f"   â€¢ ConfianÃ§a Geral: {result.confidence:.1%}")
        print(f"   â€¢ Tempo de Processamento: {processing_time:.2f}s")
        print(f"   â€¢ Resultado Esperado: {esperado}")
        
        # Principais descobertas
        if summary.get("main_findings"):
            print(f"\nğŸ” PRINCIPAIS DESCOBERTAS:")
            for finding in summary["main_findings"]:
                print(f"   â€¢ {finding}")
        
        # DetecÃ§Ã£o de anomalias
        if result.anomaly_detection:
            anomaly_data = result.anomaly_detection
            print(f"\nğŸš¨ DETECÃ‡ÃƒO DE ANOMALIAS:")
            print(f"   â€¢ Amostras analisadas: {anomaly_data['summary']['total_samples']}")
            print(f"   â€¢ Anomalias encontradas: {anomaly_data['summary']['anomalous_count']}")
            print(f"   â€¢ Casos suspeitos: {anomaly_data['summary']['suspicious_count']}")
            
            if anomaly_data["predictions"]:
                pred = anomaly_data["predictions"][0]
                print(f"   â€¢ ClassificaÃ§Ã£o: {pred['anomaly_type']}")
                print(f"   â€¢ ConfianÃ§a: {pred['confidence']:.1%}")
        
        # AnÃ¡lise financeira
        if result.financial_analysis:
            financial_data = result.financial_analysis
            print(f"\nğŸ’° ANÃLISE FINANCEIRA:")
            print(f"   â€¢ Contratos de alto risco: {financial_data['summary']['high_risk_count']}")
            
            if financial_data["predictions"]:
                pred = financial_data["predictions"][0]
                print(f"   â€¢ NÃ­vel de risco: {pred['risk_level']}")
                print(f"   â€¢ Valor estimado em risco: R$ {pred.get('estimated_value', 0):,.2f}")
        
        # Conformidade legal
        if result.legal_compliance:
            legal_data = result.legal_compliance
            print(f"\nâš–ï¸ CONFORMIDADE LEGAL:")
            compliance_rate = legal_data['summary']['compliance_rate']
            print(f"   â€¢ Taxa de conformidade: {compliance_rate:.1%}")
            
            if legal_data["predictions"]:
                pred = legal_data["predictions"][0]
                status = "Conforme" if pred["is_compliant"] else "NÃ£o Conforme"
                print(f"   â€¢ Status: {status}")
                print(f"   â€¢ ConfianÃ§a: {pred['compliance_confidence']:.1%}")
        
        # RecomendaÃ§Ãµes
        print(f"\nğŸ’¡ RECOMENDAÃ‡Ã•ES:")
        for rec in result.recommendations:
            print(f"   â€¢ {rec}")
        
        input("\nâ Pressione Enter para continuar...")

    async def _demo_chat(self):
        """DemonstraÃ§Ã£o do chat interativo"""
        
        print("\n" + "="*60)
        print("ğŸ’¬ CHAT INTERATIVO COM CIDADÃƒOGPT")
        print("="*60)
        print("ğŸ’¡ Dica: Digite 'sair' para voltar ao menu principal")
        print("ğŸ’¡ Experimente perguntas sobre transparÃªncia, contratos e corrupÃ§Ã£o")
        
        # Mostrar exemplos
        print("\nğŸ“ Exemplos de perguntas:")
        for i, cenario in enumerate(self.demo_data["cenarios_chat"], 1):
            print(f"{i}. {cenario['pergunta']}")
        
        print("\n" + "="*60)
        
        messages_history = []
        
        while True:
            user_input = input("\nğŸ§‘ VocÃª: ").strip()
            
            if user_input.lower() in ['sair', 'exit', 'quit']:
                break
                
            if not user_input:
                continue
            
            messages_history.append({"role": "user", "content": user_input})
            
            try:
                print("ğŸ¤– CidadÃ£oGPT: ğŸ”„ Pensando...")
                
                from src.ml.model_api import ChatRequest
                
                chat_request = ChatRequest(
                    messages=messages_history,
                    temperature=0.6,
                    max_tokens=512
                )
                
                response = await self.manager.chat_completion(chat_request)
                
                print(f"\nğŸ¤– CidadÃ£oGPT: {response.message}")
                
                if response.tools_used:
                    print(f"ğŸ”§ Ferramentas utilizadas: {', '.join(response.tools_used)}")
                
                if response.sources:
                    print(f"ğŸ“š Fontes: {', '.join(response.sources)}")
                
                print(f"ğŸ“Š ConfianÃ§a: {response.confidence:.1%}")
                
                messages_history.append({"role": "assistant", "content": response.message})
                
            except Exception as e:
                logger.error(f"âŒ Erro no chat: {e}")
                print(f"âŒ Erro: {e}")

    async def _demo_batch_analysis(self):
        """DemonstraÃ§Ã£o de anÃ¡lise em lote"""
        
        print("\n" + "="*60)
        print("ğŸ“Š ANÃLISE EM LOTE")
        print("="*60)
        
        # Preparar textos para anÃ¡lise em lote
        textos_lote = [
            "PregÃ£o eletrÃ´nico para material de limpeza no valor de R$ 80.000,00",
            "Contrato emergencial sem licitaÃ§Ã£o para obras no valor de R$ 15.000.000,00",
            "ConvÃªnio de cooperaÃ§Ã£o tÃ©cnica com universidade no valor de R$ 500.000,00",
            "Dispensa de licitaÃ§Ã£o para consultoria com empresa de fachada"
        ]
        
        print("ğŸ“‹ Analisando 4 contratos em lote...")
        
        try:
            from src.ml.model_api import BatchAnalysisRequest
            
            batch_request = BatchAnalysisRequest(
                texts=textos_lote,
                analysis_type="complete",
                format="json"
            )
            
            start_time = time.time()
            results = await self.manager.batch_analyze(batch_request)
            total_time = time.time() - start_time
            
            print(f"\nâœ… AnÃ¡lise concluÃ­da em {total_time:.2f}s")
            print(f"ğŸ“Š Velocidade: {len(textos_lote)/total_time:.1f} contratos/segundo")
            
            # Mostrar resultados resumidos
            print("\nğŸ“‹ RESULTADOS RESUMIDOS:")
            print("-" * 60)
            
            for i, result in enumerate(results, 1):
                summary = result.executive_summary
                print(f"{i}. Risco: {summary['overall_risk']:10} | "
                      f"Alerta: {summary['alert_level']:8} | "
                      f"ConfianÃ§a: {result.confidence:.1%}")
                print(f"   Texto: {textos_lote[i-1][:50]}...")
                
                if result.recommendations:
                    print(f"   Rec: {result.recommendations[0][:60]}...")
                print()
            
        except Exception as e:
            logger.error(f"âŒ Erro na anÃ¡lise em lote: {e}")
            print(f"âŒ Erro: {e}")
        
        input("â Pressione Enter para continuar...")

    async def _demo_benchmark(self):
        """DemonstraÃ§Ã£o do benchmark"""
        
        print("\n" + "="*60)
        print("ğŸ† BENCHMARK DE PERFORMANCE")
        print("="*60)
        
        print("ğŸ“Š Executando TransparenciaBench-BR...")
        print("âš ï¸ Nota: Usando dados sintÃ©ticos para demonstraÃ§Ã£o")
        
        try:
            config = BenchmarkConfig(
                max_samples_per_task=20,  # Reduzido para demo
                output_dir="./demo_benchmark_results",
                generate_plots=False  # Desabilitar plots para demo
            )
            
            start_time = time.time()
            results = await run_transparency_benchmark(config=config)
            total_time = time.time() - start_time
            
            print(f"\nâœ… Benchmark concluÃ­do em {total_time:.1f}s")
            
            # Mostrar resultados principais
            print("\nğŸ¯ RESULTADOS PRINCIPAIS:")
            print("-" * 40)
            print(f"ğŸ“Š Score de TransparÃªncia: {results.transparency_score:.1%}")
            print(f"ğŸ¯ F1 Score Geral: {results.overall_f1:.1%}")
            print(f"ğŸ“ˆ Accuracy Geral: {results.overall_accuracy:.1%}")
            print(f"â±ï¸ Tempo MÃ©dio: {results.average_processing_time:.3f}s")
            
            print("\nğŸ” PERFORMANCE POR TAREFA:")
            print("-" * 40)
            for task_name, metrics in results.task_metrics.items():
                task_display = task_name.replace('_', ' ').title()
                print(f"{task_display:20} | F1: {metrics.f1_score:.1%} | Acc: {metrics.accuracy:.1%}")
            
            print("\nğŸ… CAPACIDADES ESPECIALIZADAS:")
            print("-" * 40)
            print(f"ğŸš¨ DetecÃ§Ã£o de CorrupÃ§Ã£o: {results.corruption_detection_ability:.1%}")
            print(f"âš–ï¸ CompreensÃ£o Legal: {results.legal_compliance_understanding:.1%}")
            print(f"ğŸ’° AvaliaÃ§Ã£o Financeira: {results.financial_risk_assessment:.1%}")
            
            if results.compared_to_baselines:
                print("\nğŸ“ˆ COMPARAÃ‡ÃƒO COM BASELINES:")
                print("-" * 40)
                for baseline, comparison in results.compared_to_baselines.items():
                    improvement = comparison["improvement_percent"]
                    status = "ğŸ“ˆ" if improvement > 0 else "ğŸ“‰"
                    print(f"{baseline:20} | {status} {improvement:+.1f}%")
            
        except Exception as e:
            logger.error(f"âŒ Erro no benchmark: {e}")
            print(f"âŒ Erro: {e}")
        
        input("\nâ Pressione Enter para continuar...")

    async def _demo_training(self):
        """DemonstraÃ§Ã£o do processo de treinamento"""
        
        print("\n" + "="*60)
        print("ğŸ“ DEMONSTRAÃ‡ÃƒO - PIPELINE DE TREINAMENTO")
        print("="*60)
        print("âš ï¸ Nota: Esta Ã© uma demonstraÃ§Ã£o dos componentes de treinamento")
        print("   O treinamento real requer dados e recursos computacionais significativos")
        
        print("\nğŸ”§ Componentes do Pipeline:")
        print("1. ğŸ“Š Coleta de dados do Portal da TransparÃªncia")
        print("2. ğŸ”„ Processamento e anotaÃ§Ã£o automÃ¡tica") 
        print("3. ğŸ¯ Treinamento multi-tarefa especializado")
        print("4. ğŸ“ˆ AvaliaÃ§Ã£o e benchmark")
        
        choice = input("\nDeseja ver a configuraÃ§Ã£o do pipeline? (s/n): ").strip().lower()
        
        if choice == 's':
            print("\nğŸ“‹ CONFIGURAÃ‡ÃƒO DE TREINAMENTO:")
            print("-" * 40)
            
            # Mostrar configuraÃ§Ã£o de dados
            data_config = DataPipelineConfig(
                max_samples_per_type=1000,
                balance_classes=True,
                output_dir="./data/processed"
            )
            
            print("ğŸ—‚ï¸ Pipeline de Dados:")
            print(f"   â€¢ Amostras por tipo: {data_config.max_samples_per_type:,}")
            print(f"   â€¢ Balanceamento: {'Sim' if data_config.balance_classes else 'NÃ£o'}")
            print(f"   â€¢ Split treino/val/teste: {data_config.train_split:.1%}/{data_config.val_split:.1%}/{data_config.test_split:.1%}")
            
            # Mostrar configuraÃ§Ã£o de treinamento
            train_config = TrainingConfig(
                learning_rate=2e-5,
                batch_size=16,
                num_epochs=10,
                specialized_tasks=["all"]
            )
            
            print("\nğŸ“ ConfiguraÃ§Ã£o de Treinamento:")
            print(f"   â€¢ Learning rate: {train_config.learning_rate}")
            print(f"   â€¢ Batch size: {train_config.batch_size}")
            print(f"   â€¢ Ã‰pocas: {train_config.num_epochs}")
            print(f"   â€¢ Tarefas: {', '.join(train_config.specialized_tasks)}")
            
            print("\nğŸ’¡ Para executar treinamento real:")
            print("   1. Configure dados reais no Portal da TransparÃªncia")
            print("   2. Execute: python -m src.ml.training_pipeline")
            print("   3. Monitore com: tensorboard --logdir ./models/logs")
        
        input("\nâ Pressione Enter para continuar...")

    def _show_model_info(self):
        """Mostrar informaÃ§Ãµes do modelo"""
        
        print("\n" + "="*60)
        print("â„¹ï¸ INFORMAÃ‡Ã•ES DO MODELO")
        print("="*60)
        
        if self.model:
            total_params = sum(p.numel() for p in self.model.parameters())
            trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
            
            print("ğŸ¤– CIDADÃƒOGPT - ESPECIFICAÃ‡Ã•ES TÃ‰CNICAS")
            print("-" * 40)
            print(f"ğŸ“Š ParÃ¢metros totais: {total_params:,}")
            print(f"ğŸ¯ ParÃ¢metros treinÃ¡veis: {trainable_params:,}")
            print(f"ğŸ’¾ Tamanho do modelo: ~{total_params * 4 / 1024**3:.1f} GB (FP32)")
            
            print("\nğŸ”§ ARQUITETURA:")
            print(f"   â€¢ Transformer base: {self.model.config.num_hidden_layers} camadas")
            print(f"   â€¢ Hidden size: {self.model.config.hidden_size}")
            print(f"   â€¢ Attention heads: {self.model.config.num_attention_heads}")
            print(f"   â€¢ Context length: 8K tokens")
            
            print("\nğŸ¯ ESPECIALIZAÃ‡Ã•ES:")
            config = self.model.config
            if config.enable_anomaly_detection:
                print("   â€¢ âœ… DetecÃ§Ã£o de anomalias")
            if config.enable_financial_analysis:
                print("   â€¢ âœ… AnÃ¡lise de risco financeiro")
            if config.enable_legal_reasoning:
                print("   â€¢ âœ… RaciocÃ­nio jurÃ­dico")
            
            print("\nğŸ“Š ESTATÃSTICAS DE USO:")
            stats = self.manager.usage_stats
            print(f"   â€¢ RequisiÃ§Ãµes totais: {stats['total_requests']}")
            print(f"   â€¢ DetecÃ§Ãµes de anomalia: {stats['anomaly_detections']}")
            print(f"   â€¢ AnÃ¡lises financeiras: {stats['financial_analyses']}")
            print(f"   â€¢ VerificaÃ§Ãµes legais: {stats['legal_checks']}")
            print(f"   â€¢ Tempo mÃ©dio: {stats['average_processing_time']:.3f}s")
        
        print("\nğŸ’¡ COMPARAÃ‡ÃƒO COM OUTROS MODELOS:")
        print("-" * 40)
        print("CidadÃ£oGPT vs GPT-4:")
        print("   â€¢ âœ… EspecializaÃ§Ã£o em transparÃªncia pÃºblica")
        print("   â€¢ âœ… CompreensÃ£o de legislaÃ§Ã£o brasileira")
        print("   â€¢ âœ… DetecÃ§Ã£o especÃ­fica de corrupÃ§Ã£o")
        print("   â€¢ âœ… ExplicaÃ§Ãµes em portuguÃªs")
        print("   â€¢ âš¡ Processamento otimizado para contratos")
        
        print("\nğŸŒ RECURSOS ONLINE:")
        print("   â€¢ ğŸ“š DocumentaÃ§Ã£o: https://github.com/anderson-ufrj/cidadao.ai")
        print("   â€¢ ğŸ¤— Hugging Face: https://huggingface.co/neural-thinker/cidadao-ai")
        print("   â€¢ ğŸ® Demo Web: DisponÃ­vel no app.py")
        
        input("\nâ Pressione Enter para continuar...")

    def _show_credits(self):
        """Mostrar crÃ©ditos"""
        
        print("\n" + "="*60)
        print("ğŸ‘¨â€ğŸ’» CRÃ‰DITOS E INFORMAÃ‡Ã•ES")
        print("="*60)
        print("ğŸ¤– CidadÃ£oGPT - Modelo de IA para TransparÃªncia PÃºblica")
        print("ğŸ’¡ Inspirado no Kimi K2 (Moonshot AI)")
        print("ğŸ‡§ğŸ‡· Especializado para dados governamentais brasileiros")
        print()
        print("ğŸ‘¨â€ğŸ’» Desenvolvedor: Anderson Henrique da Silva")
        print("ğŸ¤– AssistÃªncia IA: Claude Code (Anthropic)")
        print("ğŸ“Š Dados: Portal da TransparÃªncia (Governo Federal)")
        print()
        print("ğŸ“„ LicenÃ§a: MIT License")
        print("ğŸŒ GitHub: https://github.com/anderson-ufrj/cidadao.ai")


async def main():
    """FunÃ§Ã£o principal"""
    
    try:
        demo = CidadaoGPTDemo()
        await demo.run_demo()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ DemonstraÃ§Ã£o interrompida. AtÃ© logo!")
    except Exception as e:
        logger.error(f"âŒ Erro na demonstraÃ§Ã£o: {e}")
        print(f"âŒ Erro: {e}")


if __name__ == "__main__":
    print("ğŸ¤– Iniciando demonstraÃ§Ã£o do CidadÃ£oGPT...")
    asyncio.run(main())